#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®­ç»ƒç›‘æ§å’Œæ£€æŸ¥ç‚¹ç®¡ç†å·¥å…·
"""

import os
import json
import time
import torch
import shutil
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import matplotlib.pyplot as plt
import numpy as np

class TrainingMonitor:
    """è®­ç»ƒè¿›åº¦ç›‘æ§å™¨"""
    
    def __init__(self, output_dir: str = "./output", log_file: str = "training_log.json"):
        self.output_dir = Path(output_dir)
        self.log_file = self.output_dir / log_file
        self.start_time = None
        self.metrics_history = []
        self.step_times = []
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def start_training(self, total_steps: int, model_name: str = ""):
        """å¼€å§‹è®­ç»ƒç›‘æ§"""
        self.start_time = time.time()
        self.total_steps = total_steps
        self.model_name = model_name
        
        # è®°å½•è®­ç»ƒå¼€å§‹ä¿¡æ¯
        start_info = {
            "start_time": datetime.now().isoformat(),
            "total_steps": total_steps,
            "model_name": model_name,
            "status": "started"
        }
        
        self._save_log(start_info)
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒç›‘æ§: {model_name}")
        print(f"   æ€»æ­¥æ•°: {total_steps:,}")
        print(f"   å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    def log_step(self, step: int, metrics: Dict[str, float], step_time: float = None):
        """è®°å½•è®­ç»ƒæ­¥éª¤"""
        current_time = time.time()
        
        if step_time is None:
            if len(self.step_times) > 0:
                step_time = current_time - self.step_times[-1]
            else:
                step_time = current_time - self.start_time if self.start_time else 0
        
        self.step_times.append(current_time)
        
        # è®°å½•æŒ‡æ ‡
        log_entry = {
            "step": step,
            "timestamp": datetime.now().isoformat(),
            "elapsed_time": current_time - self.start_time if self.start_time else 0,
            "step_time": step_time,
            "metrics": metrics
        }
        
        self.metrics_history.append(log_entry)
        
        # è®¡ç®—è¿›åº¦å’ŒETA
        progress = step / self.total_steps if hasattr(self, 'total_steps') else 0
        eta = self._estimate_eta(step)
        
        # æ˜¾ç¤ºè¿›åº¦
        if step % 10 == 0 or step == 1:  # æ¯10æ­¥æ˜¾ç¤ºä¸€æ¬¡
            self._print_progress(step, progress, eta, metrics, step_time)
        
        # å®šæœŸä¿å­˜æ—¥å¿—
        if step % 100 == 0:
            self._save_current_state()
    
    def _estimate_eta(self, current_step: int) -> str:
        """ä¼°ç®—å‰©ä½™æ—¶é—´"""
        if not hasattr(self, 'total_steps') or current_step == 0:
            return "æœªçŸ¥"
        
        # ä½¿ç”¨æœ€è¿‘çš„æ­¥éª¤æ—¶é—´è®¡ç®—å¹³å‡é€Ÿåº¦
        recent_steps = min(50, len(self.step_times))
        if recent_steps < 2:
            return "è®¡ç®—ä¸­..."
        
        recent_times = self.step_times[-recent_steps:]
        avg_step_time = (recent_times[-1] - recent_times[0]) / (recent_steps - 1)
        
        remaining_steps = self.total_steps - current_step
        remaining_seconds = remaining_steps * avg_step_time
        
        return self._format_time(remaining_seconds)
    
    def _format_time(self, seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
        if seconds < 60:
            return f"{seconds:.0f}ç§’"
        elif seconds < 3600:
            return f"{seconds/60:.0f}åˆ†é’Ÿ"
        else:
            hours = seconds // 3600
            minutes = (seconds % 3600) // 60
            return f"{hours:.0f}å°æ—¶{minutes:.0f}åˆ†é’Ÿ"
    
    def _print_progress(self, step: int, progress: float, eta: str, metrics: Dict[str, float], step_time: float):
        """æ‰“å°è®­ç»ƒè¿›åº¦"""
        # è¿›åº¦æ¡
        bar_length = 30
        filled_length = int(bar_length * progress)
        bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)
        
        # æ ¼å¼åŒ–æŒ‡æ ‡
        metrics_str = ", ".join([f"{k}: {v:.4f}" for k, v in metrics.items()])
        
        print(f"\ræ­¥éª¤ {step:,}/{getattr(self, 'total_steps', '?'):,} [{bar}] {progress*100:.1f}% | "
              f"ETA: {eta} | æ­¥æ—¶: {step_time:.2f}s | {metrics_str}", end="", flush=True)
        
        # æ¯100æ­¥æ¢è¡Œ
        if step % 100 == 0:
            print()
    
    def _save_log(self, data: Dict):
        """ä¿å­˜æ—¥å¿—"""
        try:
            with open(self.log_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜æ—¥å¿—å¤±è´¥: {e}")
    
    def _save_current_state(self):
        """ä¿å­˜å½“å‰çŠ¶æ€"""
        state = {
            "start_time": datetime.fromtimestamp(self.start_time).isoformat() if self.start_time else None,
            "total_steps": getattr(self, 'total_steps', 0),
            "model_name": getattr(self, 'model_name', ""),
            "current_step": len(self.metrics_history),
            "metrics_history": self.metrics_history[-100:],  # åªä¿å­˜æœ€è¿‘100æ­¥
            "last_update": datetime.now().isoformat()
        }
        
        self._save_log(state)
    
    def finish_training(self, final_metrics: Dict[str, float] = None):
        """ç»“æŸè®­ç»ƒç›‘æ§"""
        end_time = time.time()
        total_time = end_time - self.start_time if self.start_time else 0
        
        print(f"\n\nğŸ‰ è®­ç»ƒå®Œæˆ!")
        print(f"   æ€»è€—æ—¶: {self._format_time(total_time)}")
        print(f"   æ€»æ­¥æ•°: {len(self.metrics_history):,}")
        
        if final_metrics:
            print("   æœ€ç»ˆæŒ‡æ ‡:")
            for k, v in final_metrics.items():
                print(f"     {k}: {v:.4f}")
        
        # ä¿å­˜æœ€ç»ˆçŠ¶æ€
        final_state = {
            "status": "completed",
            "end_time": datetime.now().isoformat(),
            "total_time": total_time,
            "total_steps": len(self.metrics_history),
            "final_metrics": final_metrics or {},
            "metrics_history": self.metrics_history
        }
        
        self._save_log(final_state)
        
        # ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š
        self.generate_report()
    
    def generate_report(self):
        """ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š"""
        if not self.metrics_history:
            print("âš ï¸  æ²¡æœ‰è®­ç»ƒæ•°æ®ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
            return
        
        try:
            # æå–æŒ‡æ ‡æ•°æ®
            steps = [entry['step'] for entry in self.metrics_history]
            
            # è·å–æ‰€æœ‰æŒ‡æ ‡åç§°
            all_metrics = set()
            for entry in self.metrics_history:
                all_metrics.update(entry['metrics'].keys())
            
            # åˆ›å»ºå›¾è¡¨
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle(f'è®­ç»ƒæŠ¥å‘Š - {getattr(self, "model_name", "Unknown Model")}', fontsize=16)
            
            # æŸå¤±æ›²çº¿
            loss_metrics = [m for m in all_metrics if 'loss' in m.lower()]
            if loss_metrics:
                ax = axes[0, 0]
                for metric in loss_metrics:
                    values = [entry['metrics'].get(metric, 0) for entry in self.metrics_history]
                    ax.plot(steps, values, label=metric)
                ax.set_title('æŸå¤±æ›²çº¿')
                ax.set_xlabel('æ­¥æ•°')
                ax.set_ylabel('æŸå¤±å€¼')
                ax.legend()
                ax.grid(True)
            
            # å­¦ä¹ ç‡æ›²çº¿
            lr_metrics = [m for m in all_metrics if 'lr' in m.lower() or 'learning_rate' in m.lower()]
            if lr_metrics:
                ax = axes[0, 1]
                for metric in lr_metrics:
                    values = [entry['metrics'].get(metric, 0) for entry in self.metrics_history]
                    ax.plot(steps, values, label=metric)
                ax.set_title('å­¦ä¹ ç‡æ›²çº¿')
                ax.set_xlabel('æ­¥æ•°')
                ax.set_ylabel('å­¦ä¹ ç‡')
                ax.legend()
                ax.grid(True)
            
            # å¥–åŠ±æ›²çº¿
            reward_metrics = [m for m in all_metrics if 'reward' in m.lower()]
            if reward_metrics:
                ax = axes[1, 0]
                for metric in reward_metrics:
                    values = [entry['metrics'].get(metric, 0) for entry in self.metrics_history]
                    ax.plot(steps, values, label=metric)
                ax.set_title('å¥–åŠ±æ›²çº¿')
                ax.set_xlabel('æ­¥æ•°')
                ax.set_ylabel('å¥–åŠ±å€¼')
                ax.legend()
                ax.grid(True)
            
            # æ­¥éª¤æ—¶é—´
            step_times = [entry['step_time'] for entry in self.metrics_history if 'step_time' in entry]
            if step_times:
                ax = axes[1, 1]
                ax.plot(steps[:len(step_times)], step_times)
                ax.set_title('æ­¥éª¤è€—æ—¶')
                ax.set_xlabel('æ­¥æ•°')
                ax.set_ylabel('æ—¶é—´(ç§’)')
                ax.grid(True)
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾è¡¨
            report_path = self.output_dir / "training_report.png"
            plt.savefig(report_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"ğŸ“Š è®­ç»ƒæŠ¥å‘Šå·²ä¿å­˜: {report_path}")
            
        except Exception as e:
            print(f"âš ï¸  ç”Ÿæˆè®­ç»ƒæŠ¥å‘Šå¤±è´¥: {e}")

class CheckpointManager:
    """æ£€æŸ¥ç‚¹ç®¡ç†å™¨"""
    
    def __init__(self, output_dir: str = "./output", max_checkpoints: int = 5):
        self.output_dir = Path(output_dir)
        self.max_checkpoints = max_checkpoints
        self.checkpoints_dir = self.output_dir / "checkpoints"
        self.checkpoints_dir.mkdir(parents=True, exist_ok=True)
        
        # æ£€æŸ¥ç‚¹ä¿¡æ¯æ–‡ä»¶
        self.info_file = self.checkpoints_dir / "checkpoint_info.json"
        self.checkpoint_info = self._load_checkpoint_info()
    
    def _load_checkpoint_info(self) -> Dict:
        """åŠ è½½æ£€æŸ¥ç‚¹ä¿¡æ¯"""
        if self.info_file.exists():
            try:
                with open(self.info_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸  åŠ è½½æ£€æŸ¥ç‚¹ä¿¡æ¯å¤±è´¥: {e}")
        
        return {
            "checkpoints": [],
            "best_checkpoint": None,
            "best_metric": None,
            "best_value": None
        }
    
    def _save_checkpoint_info(self):
        """ä¿å­˜æ£€æŸ¥ç‚¹ä¿¡æ¯"""
        try:
            with open(self.info_file, 'w', encoding='utf-8') as f:
                json.dump(self.checkpoint_info, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜æ£€æŸ¥ç‚¹ä¿¡æ¯å¤±è´¥: {e}")
    
    def save_checkpoint(self, model, tokenizer, step: int, metrics: Dict[str, float], 
                       is_best: bool = False, metric_name: str = "loss"):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint_name = f"checkpoint-{step}"
        checkpoint_path = self.checkpoints_dir / checkpoint_name
        
        try:
            # ä¿å­˜æ¨¡å‹å’Œåˆ†è¯å™¨
            checkpoint_path.mkdir(exist_ok=True)
            model.save_pretrained(checkpoint_path)
            tokenizer.save_pretrained(checkpoint_path)
            
            # ä¿å­˜è®­ç»ƒçŠ¶æ€
            state_dict = {
                "step": step,
                "metrics": metrics,
                "timestamp": datetime.now().isoformat(),
                "model_name": getattr(model.config, 'name_or_path', 'unknown')
            }
            
            with open(checkpoint_path / "training_state.json", 'w', encoding='utf-8') as f:
                json.dump(state_dict, f, indent=2, ensure_ascii=False)
            
            # æ›´æ–°æ£€æŸ¥ç‚¹ä¿¡æ¯
            checkpoint_info = {
                "name": checkpoint_name,
                "step": step,
                "path": str(checkpoint_path),
                "metrics": metrics,
                "timestamp": datetime.now().isoformat(),
                "size_mb": self._get_dir_size(checkpoint_path)
            }
            
            self.checkpoint_info["checkpoints"].append(checkpoint_info)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ä½³æ£€æŸ¥ç‚¹
            if is_best or self._is_best_checkpoint(metrics, metric_name):
                self.checkpoint_info["best_checkpoint"] = checkpoint_name
                self.checkpoint_info["best_metric"] = metric_name
                self.checkpoint_info["best_value"] = metrics.get(metric_name)
                
                # åˆ›å»ºæœ€ä½³æ£€æŸ¥ç‚¹çš„ç¬¦å·é“¾æ¥
                best_link = self.checkpoints_dir / "best"
                if best_link.exists():
                    if best_link.is_symlink():
                        best_link.unlink()
                    else:
                        shutil.rmtree(best_link)
                
                try:
                    best_link.symlink_to(checkpoint_path, target_is_directory=True)
                except OSError:
                    # Windowså¯èƒ½ä¸æ”¯æŒç¬¦å·é“¾æ¥ï¼Œä½¿ç”¨å¤åˆ¶
                    shutil.copytree(checkpoint_path, best_link, dirs_exist_ok=True)
            
            # æ¸…ç†æ—§æ£€æŸ¥ç‚¹
            self._cleanup_old_checkpoints()
            
            # ä¿å­˜æ›´æ–°çš„ä¿¡æ¯
            self._save_checkpoint_info()
            
            print(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_name} ({checkpoint_info['size_mb']:.1f}MB)")
            if is_best:
                print(f"ğŸ† æ–°çš„æœ€ä½³æ£€æŸ¥ç‚¹! {metric_name}: {metrics.get(metric_name, 'N/A')}")
            
            return checkpoint_path
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
            return None
    
    def _is_best_checkpoint(self, metrics: Dict[str, float], metric_name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯æœ€ä½³æ£€æŸ¥ç‚¹"""
        if metric_name not in metrics:
            return False
        
        current_value = metrics[metric_name]
        best_value = self.checkpoint_info.get("best_value")
        
        if best_value is None:
            return True
        
        # å¯¹äºæŸå¤±ç±»æŒ‡æ ‡ï¼Œè¶Šå°è¶Šå¥½ï¼›å¯¹äºå‡†ç¡®ç‡ã€å¥–åŠ±ç­‰ï¼Œè¶Šå¤§è¶Šå¥½
        if "loss" in metric_name.lower() or "error" in metric_name.lower():
            return current_value < best_value
        else:
            return current_value > best_value
    
    def _get_dir_size(self, path: Path) -> float:
        """è·å–ç›®å½•å¤§å°(MB)"""
        total_size = 0
        try:
            for file_path in path.rglob('*'):
                if file_path.is_file():
                    total_size += file_path.stat().st_size
        except Exception:
            pass
        return total_size / 1024 / 1024
    
    def _cleanup_old_checkpoints(self):
        """æ¸…ç†æ—§æ£€æŸ¥ç‚¹"""
        checkpoints = self.checkpoint_info["checkpoints"]
        
        if len(checkpoints) <= self.max_checkpoints:
            return
        
        # æŒ‰æ­¥æ•°æ’åºï¼Œä¿ç•™æœ€æ–°çš„æ£€æŸ¥ç‚¹
        checkpoints.sort(key=lambda x: x["step"])
        
        # åˆ é™¤æœ€æ—§çš„æ£€æŸ¥ç‚¹
        to_remove = checkpoints[:-self.max_checkpoints]
        
        for checkpoint in to_remove:
            try:
                checkpoint_path = Path(checkpoint["path"])
                if checkpoint_path.exists():
                    shutil.rmtree(checkpoint_path)
                    print(f"ğŸ—‘ï¸  åˆ é™¤æ—§æ£€æŸ¥ç‚¹: {checkpoint['name']}")
            except Exception as e:
                print(f"âš ï¸  åˆ é™¤æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
        
        # æ›´æ–°æ£€æŸ¥ç‚¹åˆ—è¡¨
        self.checkpoint_info["checkpoints"] = checkpoints[-self.max_checkpoints:]
    
    def list_checkpoints(self) -> List[Dict]:
        """åˆ—å‡ºæ‰€æœ‰æ£€æŸ¥ç‚¹"""
        return self.checkpoint_info["checkpoints"]
    
    def get_best_checkpoint(self) -> Optional[str]:
        """è·å–æœ€ä½³æ£€æŸ¥ç‚¹è·¯å¾„"""
        best_name = self.checkpoint_info.get("best_checkpoint")
        if best_name:
            return str(self.checkpoints_dir / best_name)
        return None
    
    def load_checkpoint(self, checkpoint_name: str = None) -> Optional[str]:
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        if checkpoint_name is None:
            # åŠ è½½æœ€ä½³æ£€æŸ¥ç‚¹
            checkpoint_path = self.get_best_checkpoint()
        elif checkpoint_name == "latest":
            # åŠ è½½æœ€æ–°æ£€æŸ¥ç‚¹
            checkpoints = self.list_checkpoints()
            if checkpoints:
                latest = max(checkpoints, key=lambda x: x["step"])
                checkpoint_path = latest["path"]
            else:
                checkpoint_path = None
        else:
            # åŠ è½½æŒ‡å®šæ£€æŸ¥ç‚¹
            checkpoint_path = str(self.checkpoints_dir / checkpoint_name)
        
        if checkpoint_path and Path(checkpoint_path).exists():
            print(f"ğŸ“‚ åŠ è½½æ£€æŸ¥ç‚¹: {checkpoint_path}")
            return checkpoint_path
        else:
            print(f"âŒ æ£€æŸ¥ç‚¹ä¸å­˜åœ¨: {checkpoint_name or 'best'}")
            return None
    
    def print_summary(self):
        """æ‰“å°æ£€æŸ¥ç‚¹æ‘˜è¦"""
        checkpoints = self.list_checkpoints()
        
        print("\nğŸ“‹ æ£€æŸ¥ç‚¹æ‘˜è¦:")
        print(f"   æ€»æ£€æŸ¥ç‚¹æ•°: {len(checkpoints)}")
        
        if checkpoints:
            total_size = sum(cp["size_mb"] for cp in checkpoints)
            print(f"   æ€»å¤§å°: {total_size:.1f}MB")
            
            latest = max(checkpoints, key=lambda x: x["step"])
            print(f"   æœ€æ–°æ£€æŸ¥ç‚¹: {latest['name']} (æ­¥éª¤ {latest['step']:,})")
            
            best_name = self.checkpoint_info.get("best_checkpoint")
            if best_name:
                best_metric = self.checkpoint_info.get("best_metric")
                best_value = self.checkpoint_info.get("best_value")
                print(f"   æœ€ä½³æ£€æŸ¥ç‚¹: {best_name} ({best_metric}: {best_value})")
            
            print("\n   æ£€æŸ¥ç‚¹åˆ—è¡¨:")
            for cp in sorted(checkpoints, key=lambda x: x["step"]):
                metrics_str = ", ".join([f"{k}: {v:.4f}" for k, v in cp["metrics"].items()])
                print(f"     {cp['name']}: æ­¥éª¤ {cp['step']:,} | {metrics_str} | {cp['size_mb']:.1f}MB")
        else:
            print("   æ— æ£€æŸ¥ç‚¹")

def main():
    """æµ‹è¯•å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="è®­ç»ƒç›‘æ§å’Œæ£€æŸ¥ç‚¹ç®¡ç†å·¥å…·")
    parser.add_argument("--action", choices=["monitor", "checkpoints"], default="checkpoints", help="æ“ä½œç±»å‹")
    parser.add_argument("--output_dir", default="./output", help="è¾“å‡ºç›®å½•")
    
    args = parser.parse_args()
    
    if args.action == "monitor":
        # æ¼”ç¤ºè®­ç»ƒç›‘æ§
        monitor = TrainingMonitor(args.output_dir)
        monitor.start_training(1000, "test-model")
        
        # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤
        for step in range(1, 101):
            metrics = {
                "loss": 2.0 - step * 0.01,
                "learning_rate": 1e-4 * (0.99 ** step),
                "reward": step * 0.1
            }
            monitor.log_step(step, metrics)
            time.sleep(0.1)  # æ¨¡æ‹Ÿè®­ç»ƒæ—¶é—´
        
        monitor.finish_training({"final_loss": 1.0})
        
    elif args.action == "checkpoints":
        # æ˜¾ç¤ºæ£€æŸ¥ç‚¹ä¿¡æ¯
        manager = CheckpointManager(args.output_dir)
        manager.print_summary()

if __name__ == "__main__":
    main()